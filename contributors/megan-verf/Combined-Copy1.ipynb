{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d47a251-0c3e-4822-9271-d6ac5c031763",
   "metadata": {},
   "source": [
    "# ColdFusion\n",
    "### GPR-LIDAR-FUSION\n",
    "7/12/22\n",
    "\n",
    "Query the SnowEx database to extract ground based snow depth measurements, snow pit density, GPR tracks, and Lidar point clounds where there is spatial and temporal overlap in a defined area.\n",
    "\n",
    "Use the lidar snow depth measurements to inform the GPR density estimate to get SWE.\n",
    "\n",
    "Test these density/SWE estimates against snowpit values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9413b18-ec9f-44e0-8a85-a306356c2e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from snowexsql.db import get_db\n",
    "from snowexsql.data import PointData, LayerData, ImageData, SiteData\n",
    "from snowexsql.conversions import query_to_geopandas, query_to_pandas\n",
    "from snowexsql.db import get_table_attributes\n",
    "\n",
    "import datetime \n",
    "from sqlalchemy import inspect\n",
    "from sqlalchemy.sql import func\n",
    "import shapely.geometry\n",
    "from geoalchemy2.shape import from_shape\n",
    "import geoalchemy2.functions as gfunc\n",
    "\n",
    "# Imports for Lidar raster\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# some mapping widgets\n",
    "import ipyleaflet\n",
    "from ipyleaflet import Map, GeoData, Rectangle, basemaps, LayersControl, basemap_to_tiles, TileLayer, SplitMapControl, Polygon, MagnifyingGlass\n",
    "import ipywidgets\n",
    "\n",
    "# load the database\n",
    "db_name = 'snow:hackweek@db.snowexdata.org/snowex'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505e4df6-363f-4e3b-bf11-fb90cf47f3dd",
   "metadata": {},
   "source": [
    "### Define Boundingbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f5ba5e8-c0f1-4d65-acfe-872f3cd4d84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to pull out ALL point data from the database that falls within our box\n",
    "bbox_WSEN = 742000, 4322000, 747000, 4325000 # EPSG 26912?\n",
    "x1, y1, x2, y2 = bbox_WSEN\n",
    "polygon = shapely.geometry.Polygon([[x1, y1], [x1, y2], [x2, y2], [x2, y1]]) # used box() before\n",
    "wkb_element = from_shape(polygon, srid=26912) # which srid is right?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c93a8b0-cf9c-4c9f-8753-b213ab0108f1",
   "metadata": {},
   "source": [
    "### Magnaprobe Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21776628-2404-4131-a4ac-cb8c2f6a5881",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine, session = get_db(db_name)\n",
    "\n",
    "# Instrument name \n",
    "site_name = \"Grand Mesa\"\n",
    "instrument = \"magnaprobe\" \n",
    "\n",
    "# Get a session\n",
    "engine, session = get_db(db_name)\n",
    "\n",
    "# The part inside the query function is what we want back, in this case all columns for the point data\n",
    "qry = session.query(PointData.geom, PointData.easting, PointData.northing, PointData.date, PointData.value, \n",
    "                    PointData.type, PointData.instrument)\n",
    "\n",
    "# Filter by site\n",
    "qry = qry.filter(PointData.site_name == site_name)\n",
    "\n",
    "# Filter by bounding box \n",
    "qry = qry.filter(gfunc.ST_Within(PointData.geom, wkb_element))\n",
    "\n",
    "# Filter by an instrument \n",
    "qry = qry.filter(PointData.instrument == instrument) # .in_(['magnaprobe', 'pit_ruler']))\n",
    "\n",
    "# Slicing the dataset for specified dates \n",
    "date1 = datetime.date(2020,1,29)\n",
    "date2 = datetime.date(2020,2,6)\n",
    "qry = qry.filter(PointData.date >= date1)\n",
    "qry = qry.filter(PointData.date <= date2)\n",
    "\n",
    "# Execute the query and convert to geopandas in one handy function\n",
    "df = query_to_geopandas(qry, engine) #directly pass to geopandas dataframe\n",
    "print(df.head())\n",
    "\n",
    "# how many did we retrieve?\n",
    "print(f'{len(df.index)} records returned!')\n",
    "\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc40953-332f-4d05-9ab9-fc753024a6f9",
   "metadata": {},
   "source": [
    "### Snow Pit measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df00d81-37f4-4d5c-ac32-c0013da6f7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the session\n",
    "engine, session = get_db(db_name)\n",
    "\n",
    "# Find the snowpits in the defined area within given dates\n",
    "query = session.query(LayerData)\n",
    "                      # .geom, LayerData.easting, LayerData.northing, LayerData.date, LayerData.value, \n",
    "                      # LayerData.pit_id, LayerData.type, LayerData.instrument)\n",
    "\n",
    "# Filter by site (probably not needed)\n",
    "# query = query.filter(LayerData.site_name == 'Grand Mesa')\n",
    "# Filter by bounding box\n",
    "query = query.filter(gfunc.ST_Within(LayerData.geom, wkb_element))\n",
    "# Filter by type (pit density)\n",
    "query = query.filter(LayerData.type == \"density\")\n",
    "# Slicing the dataset for specified dates \n",
    "date1 = datetime.date(2020,1,29)\n",
    "date2 = datetime.date(2020,2,6)\n",
    "query = query.filter(LayerData.date >= date1)\n",
    "query = query.filter(LayerData.date <= date2)\n",
    "\n",
    "count = query.count() \n",
    "print(count, \" Snowpit density measurements returned!\\n\") \n",
    "\n",
    "'''\n",
    "# Execute the query and convert to geopandas in one handy function\n",
    "df = query_to_geopandas(query, engine) #directly pass to geopandas dataframe\n",
    "print(df.head())\n",
    "\n",
    "# how many did we retrieve?\n",
    "print(f'{len(df.index)} records returned!')\n",
    "'''\n",
    "\n",
    "# convert to pandas dataframe  \n",
    "df = query_to_pandas(query, engine)  \n",
    "# df = df.sort_values(by = ['date'])\n",
    "# print(df.head())\n",
    "\n",
    "# create list of the unique dates (LayerData will have a lot of repeated dates, we only need a list per visit, not per measurement)\n",
    "locations = sorted(df['pit_id'].unique())\n",
    "count = len(locations) \n",
    "print(count, \" Snowpit density locations returned!\\n\") \n",
    "\n",
    "\n",
    "# Plot sites\n",
    "plt.scatter(df['easting'], df['northing'])\n",
    "\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd218a0c-faaf-4d60-9dd9-586f06cab797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Snowpit density measurements\n",
    "# Request the average (avg) of Layer data casted as a float. We have to cast to a float in the layer table because all main values are stored as a string to\n",
    "# ...accommodate the hand hardness.\n",
    "qry = session.query(func.avg(LayerData.value.cast(Float)))\n",
    "# Filter our query only to density\n",
    "qry = qry.filter(LayerData.type=='density')\n",
    "# Request the data\n",
    "rho_avg_all = qry.all()\n",
    "# Request the Average Density of Just 1S1\n",
    "rho_avg_1s1 = qry.filter(LayerData.site_id == site_id).limit(1)\n",
    "# This is a gotcha. The data in layer data only is stored as a string to accommodate the hand hardness values\n",
    "print(f\"Average density of all pits is {rho_avg_all[0][0]:0.0f} kg/m3\")\n",
    "print(f\"Average density of pit 1S1 is {rho_avg_1s1[0][0]:0.0f} kg/m3\")\n",
    "# Cast Densities to float\n",
    "rho_avg_all = float(rho_avg_all[0][0])\n",
    "rho_avg_1s1 = float(rho_avg_1s1[0][0])\n",
    "\n",
    "# Can use LayerData.pit_id to average over"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd303626-38cf-4f74-93f7-707062243d84",
   "metadata": {},
   "source": [
    "### GPR Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75689698-1cf9-45b6-9dfd-708172824a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the GPR Dates\n",
    "\n",
    "# Start the session\n",
    "engine, session = get_db(db_name)\n",
    "\n",
    "# Define the GPR instrument identifier\n",
    "bsu_gpr_instrument_name = \"pulse EKKO Pro multi-polarization 1 GHz GPR\"\n",
    "\n",
    "# Query the Pointdata to isolate by GPR instrument\n",
    "query = session.query(PointData.date)\n",
    "query = query.filter(PointData.instrument == bsu_gpr_instrument_name)\n",
    "\n",
    "# convert to pandas dataframe  \n",
    "df = query_to_pandas(query, engine)  \n",
    "\n",
    "# create list of the unique dates (LayerData will have a lot of repeated dates, we only need a list per visit, not per measurement)\n",
    "GPR_dates = sorted(df['date'].unique())\n",
    "\n",
    "# Print the given dates\n",
    "print(GPR_dates)\n",
    "\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e06926-3f3e-4911-a1b6-3ca0d019dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the session\n",
    "engine, session = get_db(db_name)\n",
    "\n",
    "# Limit the size of the GPR data for initial processing and plot\n",
    "query = session.query(PointData)\n",
    "query = query.filter(PointData.instrument == bsu_gpr_instrument_name)\n",
    "query = query.distinct().order_by(func.random()).limit(100) #all()\n",
    "\n",
    "bsu_gpr_sample = query_to_geopandas(query, engine)\n",
    "\n",
    "bsu_gpr_sample.plot()\n",
    "\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66b4898-7784-4b16-ac1f-81c420233a4a",
   "metadata": {},
   "source": [
    "### Lidar Raster (In-Progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6af816-6634-4a2a-8532-64f8b4cf8667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the session\n",
    "engine, session = get_db(db_name)\n",
    "\n",
    "query = session.query(ImageData.units)\n",
    "query = query.filter(ImageData.observers == \"ASO Inc.\")\n",
    "query = query.filter(ImageData.type == \"depth\")\n",
    "query = query.distinct()\n",
    "result = query.all()\n",
    "print(result)\n",
    "\n",
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
